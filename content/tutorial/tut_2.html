---
title: "Introduction to Parallel Computing"
output: html_document
---



<style type="text/css">
body{ /* Normal  */
      font-size: 14px;
  }
h1 { /* Header 1 */
  font-size: 26px;
  color: DarkGreen;
}
h2 { /* Header 2 */
    font-size: 22px;
  color: DarkGreen;
}
code.r{ /* Code block */
    font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
    font-size: 12px;
}
</style>
<p>The goal of this series of tutorials is to teach ecologists on how to use parallel computing to perform null models. I thus assume that you already know what a null model is. :) Otherwise, there is an excellent book on the subject (Gotelli and Graves, 1996) that is freely available to download <a href="https://www.uvm.edu/~ngotelli/nullmodelspage.html">here</a>.</p>
<p>Why use parallel processing? The simple answer is time. If something takes less time done through parallel processing, why not do it? Computers nowadays have multi core processors with sufficient amount of memory available to run parallel processing. Instead of waiting a long time for a task to complete, one can divide the taks to run in multiple cores and thus obtain outputs much faster.</p>
<p>Before deciding to parallelize your code, remember that there is a trade-off between performance and simplicity. It takes some time to set up the parallel cluster so if your code already runs fast it is not worth it. If your code repeats a similar task over and over (e.g., bootstraping) then it is recommended to parallize to improve performance. Hence, parallel computing is ideal for null models.</p>
<p>While there are many good tutorials on parallel computing in R out there, I think it is better to provide a small introduction on how to set up a parallel cluster and how to start coding in parallel before jumping on the null models.</p>
<div id="r-packages" class="section level1">
<h1>R packages</h1>
<p>There are many packages to run parallel processing in R. Here are a few examples:</p>
<ul>
<li>parallel</li>
<li>snow</li>
<li>doSNOW</li>
<li>doParallel</li>
<li>foreach</li>
</ul>
<p>First install packages <code>install.packages(&quot;doParallel&quot;)</code>. The <em>doParallel</em> library installs both <em>parallel</em> and <em>foreach</em> packages.</p>
<p>Then set up a parallel cluster. Use the function <code>detectCores</code> from the <em>parallel</em> library to detect the number of cores in your computer. It is always recommended to leave one core free for the computer to run other processes. For simplicity we will use 2 cores in this example.</p>
<pre class="r"><code>library(doParallel)</code></pre>
<pre><code>## Loading required package: foreach</code></pre>
<pre><code>## Loading required package: iterators</code></pre>
<pre><code>## Loading required package: parallel</code></pre>
<pre class="r"><code>detectCores()</code></pre>
<pre><code>## [1] 4</code></pre>
<pre class="r"><code>cl &lt;- makeCluster(2, type = &#39;PSOCK&#39;)</code></pre>
<p>This will create a <em>Parallel Socket Cluster</em> (PSOCK). This type of cluster only starts with the base packages and thus you need to export additional variables, functions and packages to the cluster (see further below) if you need them in your parallel code.</p>
<p>You can also create a FORK cluster, which has better capabilities to manage memory and already contain all the variables from the local environment (i.e., no need for export) since all the cores share the same memory. For this, use: <code>cl &lt;- makeCluster(2, type = 'FORK')</code> Note, however, that Windows does not support FORK clusters.</p>
</div>
<div id="foreach-loops" class="section level1">
<h1>foreach loops</h1>
<p>An intuitive way to perform a parallel process is to use the foreach function which looks like a for loop but operates as a lapply() function. As a first example we will perform the foreach function in sequential mode by using %do%</p>
<pre class="r"><code>library(foreach)
foreach(i = 1:6) %do% {
  sqrt(i)
}</code></pre>
<pre><code>## [[1]]
## [1] 1
## 
## [[2]]
## [1] 1.414214
## 
## [[3]]
## [1] 1.732051
## 
## [[4]]
## [1] 2
## 
## [[5]]
## [1] 2.236068
## 
## [[6]]
## [1] 2.44949</code></pre>
<p>In the example above we applied <code>sqrt()</code> on each “i”. By default, foreach returns the output in a list format. You can combine the results in different ways. For instance if you want a vector output you can add the argument “.combine = c”.</p>
<pre class="r"><code>foreach(i = 1:6, .combine = c) %do% {
  sqrt(i)
}</code></pre>
<pre><code>## [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490</code></pre>
<p>If you want to use the foreach in parallel mode, you need to change %do% to %dopar%. You also need to register the cluster. Here we use the <em>doParallel</em> package to do this.</p>
<pre class="r"><code>registerDoParallel(cl)

foreach(i = 1:6, .combine = c) %dopar% {
  sqrt(i)
}</code></pre>
<pre><code>## [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490</code></pre>
<p>If you want to use a variable or object from the global environment in the parallel cluster, you first need to export it either using the <code>clusterExport</code> function, or using the .export argument in the foreach function. Here I use the .export argument for exporting.</p>
<pre class="r"><code>var1 &lt;-10
var2 &lt;-5

foreach(i = 1:6, .combine = c, .export = c(&quot;var1&quot;,&quot;var2&quot;)) %dopar% {
  (var1+var2)*i
}</code></pre>
<pre><code>## Warning in e$fun(obj, substitute(ex), parent.frame(), e$data): already
## exporting variable(s): var1, var2</code></pre>
<pre><code>## [1] 15 30 45 60 75 90</code></pre>
<p>If you need to use a particular function in the parallel cluster, you also need to export it. Here I use the <code>clusterExport</code> function.</p>
<pre class="r"><code>is_even &lt;- function(x) x %% 2 == 0

clusterExport(cl, c(&quot;var1&quot;,&quot;var2&quot;,&quot;is_even&quot;))

foreach(i = 1:6, .combine = c) %dopar% {
  is_even((var1+var2)*i)
}</code></pre>
<pre><code>## [1] FALSE  TRUE FALSE  TRUE FALSE  TRUE</code></pre>
<p>If you need to use a function from a R package in the parallel cluster, you need to export the package in the cluster as well. This can be done by the argument “.package” in the foreach function or by using the <code>ClusterEvalQ</code> function.</p>
<p>Let’s use the ChickWeigth dataset which contains the variables weigth, Time, Chick and Diet. We want to compute the growth of each chick (i.e., weigth ~ Time). We can use the dplyr package to subset each chick from the dataset and then apply the <code>lm</code> function to each one separately. Here we want the coefficients of the linear model as a result and we will combine them by rows by using “.combine = rbind”.</p>
<pre class="r"><code>data(&quot;ChickWeight&quot;)
clusterEvalQ(cl,library(&quot;dplyr&quot;))</code></pre>
<pre><code>## [[1]]
## [1] &quot;dplyr&quot;     &quot;stats&quot;     &quot;graphics&quot;  &quot;grDevices&quot; &quot;utils&quot;     &quot;datasets&quot; 
## [7] &quot;methods&quot;   &quot;base&quot;     
## 
## [[2]]
## [1] &quot;dplyr&quot;     &quot;stats&quot;     &quot;graphics&quot;  &quot;grDevices&quot; &quot;utils&quot;     &quot;datasets&quot; 
## [7] &quot;methods&quot;   &quot;base&quot;</code></pre>
<pre class="r"><code>clusterExport(cl,&quot;ChickWeight&quot;)

length(unique(ChickWeight$Chick))</code></pre>
<pre><code>## [1] 50</code></pre>
<pre class="r"><code>#there are 50 unique chicks in this data

Growth_coeff&lt;- foreach(i = 1:50, .combine = rbind, .packages = &quot;dplyr&quot;) %dopar% {
  temp_data &lt;- ChickWeight %&gt;% filter(Chick == i)
  Growth = lm(weight ~ Time, data = temp_data)
  coefficients(Growth)
}

head(Growth_coeff)</code></pre>
<pre><code>##          (Intercept)      Time
## result.1    24.46544  7.987899
## result.2    24.72485  8.719861
## result.3    23.17955  8.487370
## result.4    32.86568  6.088640
## result.5    16.89563 10.055362
## result.6    44.12343  6.378006</code></pre>
<p>In the example above the <code>combine = .rbind</code> argument combined <code>coefficients(Growth)</code> into the <code>Growth_coeff</code> output.</p>
<p>Finally, let’s see how much time do we save by using the parallelized code. In this case we will repeat the above code 100 times and use the <code>system.time</code> function to determine how much times it takes to run.</p>
<p>First in sequential mode (%do%)</p>
<pre class="r"><code>trials &lt;- 100
system.time({
  Growth_coeff &lt;- foreach(icount(trials), .combine=rbind, .packages = &quot;dplyr&quot;) %do% {
    
    temp_coeff&lt;-matrix(numeric(),ncol=2,nrow=50)
    for(i in 1:50){
      temp_data &lt;- ChickWeight %&gt;% filter(Chick == i)
      Growth = lm(weight ~ Time, data = temp_data)
      temp_coeff[i,]=coefficients(Growth)
    }
   temp_coeff
  }
})</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre><code>##    user  system elapsed 
##   10.68    0.17   11.03</code></pre>
<p>And now in parallel mode (%dopar%)</p>
<pre class="r"><code>trials &lt;- 100
system.time({
  Growth_coeff &lt;- foreach(icount(trials), .combine=rbind, .packages = &quot;dplyr&quot;) %dopar% {
    
    temp_coeff&lt;-matrix(numeric(),ncol=2,nrow=50)
    for(i in 1:50){
      temp_data &lt;- ChickWeight %&gt;% filter(Chick == i)
      Growth = lm(weight ~ Time, data = temp_data)
      temp_coeff[i,]=coefficients(Growth)
    }
   temp_coeff
  }
})</code></pre>
<pre><code>##    user  system elapsed 
##    0.11    0.02    7.20</code></pre>
<p>As you can see, the script takes more than 10 seconds in sequential mode but less than 7 seconds in parallel mode.</p>
</div>
